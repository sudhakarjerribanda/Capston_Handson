{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYt8_GmFOOch",
        "outputId": "856e7250-9917-41dd-f6cf-a0f1cef8b081"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'US_senate_simulation'...\n",
            "remote: Enumerating objects: 732, done.\u001b[K\n",
            "remote: Counting objects: 100% (139/139), done.\u001b[K\n",
            "remote: Compressing objects: 100% (136/136), done.\u001b[K\n",
            "remote: Total 732 (delta 83), reused 4 (delta 3), pack-reused 593 (from 1)\u001b[K\n",
            "Receiving objects: 100% (732/732), 5.67 MiB | 21.19 MiB/s, done.\n",
            "Resolving deltas: 100% (348/348), done.\n",
            "/content/US_senate_simulation\n",
            "d1450a03474f9b0966f0cea27c98ec16ca8f8fc2\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Kulsoom-ri/US_senate_simulation.git\n",
        "%cd US_senate_simulation\n",
        "!git rev-parse HEAD\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q \"openai>=1.40.0\" \"google-generativeai>=0.7.2\" nltk\n",
        "import nltk; nltk.download('stopwords')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dw82HyInOTh_",
        "outputId": "30f6dc0a-37d0-4dd4-ca29-df1e5246c7a0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# REQUIRED: put your real keys\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\"     # if using OpenAI\n",
        "os.environ[\"GEMINI_API_KEY\"]  = \"AIzaSyBiSuTuP7OdmHI_yBJ_Vnle_x779kHO4Z0\"    # if using Gemini\n",
        "\n",
        "# Choose which provider the simulation should use under the hood:\n",
        "#   \"openai\" or \"gemini\"\n",
        "os.environ[\"LLM_PROVIDER\"] = \"openai\"      # <- change to \"gemini\" to switch\n",
        "\n",
        "# Default model per provider (you can override later)\n",
        "os.environ[\"LLM_MODEL\"] = \"gpt-4o-mini\"    # for OpenAI, e.g. \"gpt-4o-mini\"\n",
        "# os.environ[\"LLM_MODEL\"] = \"gemini-1.5-pro\"  # for Gemini\n"
      ],
      "metadata": {
        "id": "7nexJhGMOgJk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile llm_client.py\n",
        "from typing import List, Dict, Optional\n",
        "import os\n",
        "\n",
        "class LLMClient:\n",
        "    def generate(self, messages: List[Dict], temperature: float = 0.2,\n",
        "                 max_tokens: int = 1024, seed: Optional[int] = None) -> str:\n",
        "        raise NotImplementedError\n",
        "\n",
        "class OpenAIClient(LLMClient):\n",
        "    def __init__(self, model: str = None):\n",
        "        from openai import OpenAI\n",
        "        self.client = OpenAI()\n",
        "        self.model = model or os.environ.get(\"LLM_MODEL\", \"gpt-4o-mini\")\n",
        "\n",
        "    def generate(self, messages, temperature=0.2, max_tokens=1024, seed=None):\n",
        "        resp = self.client.chat.completions.create(\n",
        "            model=self.model,\n",
        "            messages=messages,\n",
        "            temperature=temperature,\n",
        "            max_tokens=max_tokens,\n",
        "            **({\"seed\": seed} if seed is not None else {})\n",
        "        )\n",
        "        return resp.choices[0].message.content\n",
        "\n",
        "class GeminiClient(LLMClient):\n",
        "    def __init__(self, model: str = None):\n",
        "        import google.generativeai as genai\n",
        "        genai.configure(api_key=os.environ.get(\"GEMINI_API_KEY\", \"\"))\n",
        "        self.genai = genai\n",
        "        self.model_name = model or os.environ.get(\"LLM_MODEL\", \"gemini-1.5-pro\")\n",
        "        self.model = genai.GenerativeModel(self.model_name)\n",
        "\n",
        "    def generate(self, messages, temperature=0.2, max_tokens=1024, seed=None):\n",
        "        # Collapse chat turns to a single prompt for Gemini\n",
        "        sys = \"\\n\".join([m[\"content\"] for m in messages if m[\"role\"] == \"system\"])\n",
        "        convo = [m[\"content\"] for m in messages if m[\"role\"] in (\"user\", \"assistant\")]\n",
        "        prompt = ((\"System:\\n\"+sys+\"\\n\\n\") if sys else \"\") + \"\\n\\n\".join(convo)\n",
        "        resp = self.model.generate_content(\n",
        "            prompt,\n",
        "            generation_config=self.genai.types.GenerationConfig(\n",
        "                temperature=temperature,\n",
        "                max_output_tokens=max_tokens,\n",
        "            )\n",
        "        )\n",
        "        return resp.text\n",
        "\n",
        "def make_llm():\n",
        "    provider = (os.environ.get(\"LLM_PROVIDER\", \"openai\") or \"openai\").lower()\n",
        "    model = os.environ.get(\"LLM_MODEL\")\n",
        "    if provider == \"openai\":\n",
        "        return OpenAIClient(model)\n",
        "    elif provider == \"gemini\":\n",
        "        return GeminiClient(model)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown LLM_PROVIDER={provider}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HoQGm1zOtdH",
        "outputId": "dc99e8f9-1596-4018-c551-dd02b739280b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing llm_client.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile groq.py\n",
        "# Local shim so `from groq import Groq` works without the groq SDK/key.\n",
        "# It adapts `client.chat.completions.create(...)` to our provider-agnostic client.\n",
        "\n",
        "from types import SimpleNamespace\n",
        "from llm_client import make_llm\n",
        "\n",
        "class _ChatCompletions:\n",
        "    def __init__(self, llm):\n",
        "        self.llm = llm\n",
        "    def create(self, model, messages, temperature=0.2, max_tokens=1024, **kwargs):\n",
        "        text = self.llm.generate(messages, temperature=temperature, max_tokens=max_tokens, seed=kwargs.get(\"seed\"))\n",
        "        # Return an OpenAI-like structure\n",
        "        return SimpleNamespace(choices=[SimpleNamespace(message=SimpleNamespace(content=text))])\n",
        "\n",
        "class _Chat:\n",
        "    def __init__(self, llm):\n",
        "        self.completions = _ChatCompletions(llm)\n",
        "\n",
        "class Groq:\n",
        "    def __init__(self, api_key=None):\n",
        "        llm = make_llm()\n",
        "        self.chat = _Chat(llm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvWngOwzOvNy",
        "outputId": "894eebb6-fd86-427f-ac53-f8fe5c8ff1e0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing groq.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Small safety tweak: if results.py imports nltk.stopwords before download,\n",
        "# this monkeypatch helps avoid the LookupError in fresh sessions.\n",
        "import nltk\n",
        "try:\n",
        "    from nltk.corpus import stopwords\n",
        "    _ = stopwords.words('english')\n",
        "except LookupError:\n",
        "    nltk.download('stopwords')\n"
      ],
      "metadata": {
        "id": "utgqR9C4Ow2b"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python run_basic.py \\\n",
        "  --rounds 2 \\\n",
        "  --bills data/bills_sample.csv \\\n",
        "  --out results/baseline.jsonl\n",
        "\n",
        "!python results.py \\\n",
        "  --in results/baseline.jsonl \\\n",
        "  --compare data/ground_truth_votes.csv \\\n",
        "  --out results/baseline_metrics.json\n",
        "\n",
        "!sed -n '1,200p' results/baseline_metrics.json\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaFX2mgTOy7v",
        "outputId": "26b38ff6-8a9d-4884-bc0b-a8d6f3ed5b0b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/US_senate_simulation/run_basic.py\", line 13, in <module>\n",
            "    senators_df = pd.read_excel(data_file, sheet_name='senators_data')\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pandas/io/excel/_base.py\", line 495, in read_excel\n",
            "    io = ExcelFile(\n",
            "         ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pandas/io/excel/_base.py\", line 1550, in __init__\n",
            "    ext = inspect_excel_format(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pandas/io/excel/_base.py\", line 1402, in inspect_excel_format\n",
            "    with get_handle(\n",
            "         ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\", line 882, in get_handle\n",
            "    handle = open(handle, ioargs.mode)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'senators_data.xlsx'\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/US_senate_simulation/results.py\", line 382, in <module>\n",
            "    main()\n",
            "  File \"/content/US_senate_simulation/results.py\", line 316, in main\n",
            "    bills_df = pd.read_excel(\"senators_data.xlsx\", sheet_name=\"bills_data\")\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pandas/io/excel/_base.py\", line 495, in read_excel\n",
            "    io = ExcelFile(\n",
            "         ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pandas/io/excel/_base.py\", line 1550, in __init__\n",
            "    ext = inspect_excel_format(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pandas/io/excel/_base.py\", line 1402, in inspect_excel_format\n",
            "    with get_handle(\n",
            "         ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\", line 882, in get_handle\n",
            "    handle = open(handle, ioargs.mode)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'senators_data.xlsx'\n",
            "sed: can't read results/baseline_metrics.json: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"LLM_PROVIDER\"] = \"gemini\"\n",
        "os.environ[\"LLM_MODEL\"] = \"gemini-1.5-pro\"   # (optional) explicit model\n",
        "\n",
        "!python run_basic.py \\\n",
        "  --rounds 2 \\\n",
        "  --bills data/bills_sample.csv \\\n",
        "  --out results/variation_gemini.jsonl\n",
        "\n",
        "!python results.py \\\n",
        "  --in results/variation_gemini.jsonl \\\n",
        "  --compare data/ground_truth_votes.csv \\\n",
        "  --out results/variation_gemini_metrics.json\n",
        "\n",
        "!sed -n '1,200p' results/variation_gemini_metrics.json\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKuLbIpZO0IW",
        "outputId": "1e56c2fc-b436-49ef-9662-107b76a408e6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/US_senate_simulation/run_basic.py\", line 13, in <module>\n",
            "    senators_df = pd.read_excel(data_file, sheet_name='senators_data')\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pandas/io/excel/_base.py\", line 495, in read_excel\n",
            "    io = ExcelFile(\n",
            "         ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pandas/io/excel/_base.py\", line 1550, in __init__\n",
            "    ext = inspect_excel_format(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pandas/io/excel/_base.py\", line 1402, in inspect_excel_format\n",
            "    with get_handle(\n",
            "         ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\", line 882, in get_handle\n",
            "    handle = open(handle, ioargs.mode)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'senators_data.xlsx'\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/US_senate_simulation/results.py\", line 382, in <module>\n",
            "    main()\n",
            "  File \"/content/US_senate_simulation/results.py\", line 316, in main\n",
            "    bills_df = pd.read_excel(\"senators_data.xlsx\", sheet_name=\"bills_data\")\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pandas/io/excel/_base.py\", line 495, in read_excel\n",
            "    io = ExcelFile(\n",
            "         ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pandas/io/excel/_base.py\", line 1550, in __init__\n",
            "    ext = inspect_excel_format(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pandas/io/excel/_base.py\", line 1402, in inspect_excel_format\n",
            "    with get_handle(\n",
            "         ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\", line 882, in get_handle\n",
            "    handle = open(handle, ioargs.mode)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'senators_data.xlsx'\n",
            "sed: can't read results/variation_gemini_metrics.json: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dpaw1331O5rp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}