{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## A) Overwrite backend with the Agent (planner/executor/aggregator + traces)"
      ],
      "metadata": {
        "id": "PRoYLn3EapHc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        },
        "id": "rXV0zUPJanIS",
        "outputId": "b0bcb5c5-e96d-4211-a5dc-d2c0d83160bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing Week_7/backend/agent_runtime.py\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'Week_7/backend/agent_runtime.py'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2675203439.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'writefile'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Week_7/backend/agent_runtime.py'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'import math, time, json, uuid, re, csv, io\\nfrom pathlib import Path\\nfrom typing import Dict, Any, List, Optional, Tuple\\n\\n# --------------- Guardrails -----------------\\nUNSAFE_TERMS = {\"nsfw\", \"violent\", \"illegal\", \"weapon\", \"blood\", \"gore\"}\\nMAX_HOPS     = 4\\nREQ_TIMEOUT  = 120  # seconds total per /agent call\\n\\ndef blocked_by_guardrails(text: str) -> Optional[str]:\\n    t = text.lower()\\n    for bad in UNSAFE_TERMS:\\n        if bad in t:\\n            return bad\\n    return None\\n\\n# --------------- Tools ----------------------\\n\\nclass Tools:\\n    \"\"\"\\n    Toolkit: ProjectQA (stub), Stable Diffusion, Calculator, CSV Summarizer.\\n    SD callable must be injected so we don\\'t import diffusers here.\\n    \"\"\"\\n    def __init__(self, sd_callable, negative_prompt: str, size: Tuple[int,int]):\\n        self.sd_callable = sd_callable\\n        self.negative_prompt = negative_prompt\\n        self.size = size  # (W, H)\\n\\n    def tool_project_qa(self, query: str) -> Tuple[str, List[Dict[str,str]]]:\\n        # TODO: plug your real Week-6 Graph-RAG / Multi-Hop here\\n        citations = [\\n            {\"title\": \"Week 7 Repo\", \"url\": \"https://github.com/sudhakarjerribanda/Capston_Handson/tree/main/Week_7\"},\\n            {\"title\": \"Task 1 Colab\", \"url\": \"https://colab.researc...\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m       \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2471\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2473\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2474\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-98>\u001b[0m in \u001b[0;36mwritefile\u001b[0;34m(self, line, cell)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/magics/osm.py\u001b[0m in \u001b[0;36mwritefile\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m         \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'a'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Week_7/backend/agent_runtime.py'"
          ]
        }
      ],
      "source": [
        "%%writefile Week_7/backend/agent_runtime.py\n",
        "import math, time, json, uuid, re, csv, io\n",
        "from pathlib import Path\n",
        "from typing import Dict, Any, List, Optional, Tuple\n",
        "\n",
        "# --------------- Guardrails -----------------\n",
        "UNSAFE_TERMS = {\"nsfw\", \"violent\", \"illegal\", \"weapon\", \"blood\", \"gore\"}\n",
        "MAX_HOPS     = 4\n",
        "REQ_TIMEOUT  = 120  # seconds total per /agent call\n",
        "\n",
        "def blocked_by_guardrails(text: str) -> Optional[str]:\n",
        "    t = text.lower()\n",
        "    for bad in UNSAFE_TERMS:\n",
        "        if bad in t:\n",
        "            return bad\n",
        "    return None\n",
        "\n",
        "# --------------- Tools ----------------------\n",
        "\n",
        "class Tools:\n",
        "    \"\"\"\n",
        "    Toolkit: ProjectQA (stub), Stable Diffusion, Calculator, CSV Summarizer.\n",
        "    SD callable must be injected so we don't import diffusers here.\n",
        "    \"\"\"\n",
        "    def __init__(self, sd_callable, negative_prompt: str, size: Tuple[int,int]):\n",
        "        self.sd_callable = sd_callable\n",
        "        self.negative_prompt = negative_prompt\n",
        "        self.size = size  # (W, H)\n",
        "\n",
        "    def tool_project_qa(self, query: str) -> Tuple[str, List[Dict[str,str]]]:\n",
        "        # TODO: plug your real Week-6 Graph-RAG / Multi-Hop here\n",
        "        citations = [\n",
        "            {\"title\": \"Week 7 Repo\", \"url\": \"https://github.com/sudhakarjerribanda/Capston_Handson/tree/main/Week_7\"},\n",
        "            {\"title\": \"Task 1 Colab\", \"url\": \"https://colab.research.google.com/drive/1yZd5zUUmNjeDH-_mpVEkNCO4fonsmW69?usp=sharing\"}\n",
        "        ]\n",
        "        ans = f\"(ProjectQA stub) For query: {query}\\n- Use Graph-RAG evidence cards, IMRaD blocks, BDI/trust gauge, PHI sanitizer badge.\"\n",
        "        return ans, citations\n",
        "\n",
        "    def tool_sd_generate(self, prompt: str, steps: int = 25, guidance: float = 7.5, fn_prefix: str = \"agent\") -> str:\n",
        "        \"\"\"\n",
        "        Returns image filename saved under Week_7/diffusion.\n",
        "        \"\"\"\n",
        "        W, H = self.size\n",
        "        filename = self.sd_callable(\n",
        "            prompt=prompt,\n",
        "            negative_prompt=self.negative_prompt,\n",
        "            steps=steps,\n",
        "            guidance=guidance,\n",
        "            height=H,\n",
        "            width=W,\n",
        "            filename_prefix=fn_prefix\n",
        "        )\n",
        "        return filename\n",
        "\n",
        "    def tool_calculator(self, expr: str) -> str:\n",
        "        \"\"\"\n",
        "        Very small safe calculator: digits, + - * / ( ) . ^ and spaces only.\n",
        "        \"\"\"\n",
        "        if not re.fullmatch(r\"[0-9\\.\\+\\-\\*\\/\\(\\)\\s\\^]+\", expr):\n",
        "            return \"Calculator refused: unsupported characters.\"\n",
        "        try:\n",
        "            # implement ^ as ** for exponent\n",
        "            expr_py = expr.replace(\"^\", \"**\")\n",
        "            val = eval(expr_py, {\"__builtins__\": {}}, {})\n",
        "            return str(val)\n",
        "        except Exception as e:\n",
        "            return f\"Calculator error: {e}\"\n",
        "\n",
        "    def tool_csv_summary(self, csv_text: str, top_k: int = 3) -> str:\n",
        "        \"\"\"\n",
        "        Summarize a small CSV (e.g., latency logs).\n",
        "        \"\"\"\n",
        "        try:\n",
        "            f = io.StringIO(csv_text)\n",
        "            rows = list(csv.DictReader(f))\n",
        "            n = len(rows)\n",
        "            if n == 0:\n",
        "                return \"CSV has no rows.\"\n",
        "            cols = rows[0].keys()\n",
        "            # try to summarize numeric columns by mean\n",
        "            means = {}\n",
        "            for c in cols:\n",
        "                vals = []\n",
        "                for r in rows:\n",
        "                    try:\n",
        "                        vals.append(float(r[c]))\n",
        "                    except:\n",
        "                        pass\n",
        "                if vals:\n",
        "                    means[c] = sum(vals) / max(1, len(vals))\n",
        "            head = rows[:top_k]\n",
        "            return f\"Rows: {n}\\nMeans: {means}\\nHead: {head}\"\n",
        "        except Exception as e:\n",
        "            return f\"CSV summary error: {e}\"\n",
        "\n",
        "# --------------- Planner / Executor / Aggregator ---------------\n",
        "\n",
        "class Agent:\n",
        "    def __init__(self, tools: Tools):\n",
        "        self.tools = tools\n",
        "\n",
        "    def plan(self, user_input: str, hops_done: int) -> Dict[str, Any]:\n",
        "        \"\"\"Very simple heuristic router.\"\"\"\n",
        "        text = user_input.lower()\n",
        "        if any(k in text for k in [\"image\", \"diagram\", \"illustration\", \"infographic\", \"generate\", \"sd\"]):\n",
        "            return {\"tool\": \"sd\", \"args\": {\n",
        "                \"prompt\": user_input + \", flat vector, teal+indigo accents, rounded cards, subtle shadows, clean typography\"\n",
        "            }}\n",
        "        if \"calc:\" in text or \"calculate\" in text or re.search(r\"[0-9].*[\\+\\-\\*\\/\\^].*[0-9]\", text):\n",
        "            # allow \"calc: 2+2\"\n",
        "            expr = user_input.split(\"calc:\", 1)[1].strip() if \"calc:\" in text else user_input\n",
        "            return {\"tool\": \"calc\", \"args\": {\"expr\": expr}}\n",
        "        if \"csv:\" in text:\n",
        "            csv_text = user_input.split(\"csv:\", 1)[1]\n",
        "            return {\"tool\": \"csv\", \"args\": {\"csv_text\": csv_text}}\n",
        "        # default → Project QA\n",
        "        return {\"tool\": \"qa\", \"args\": {\"query\": user_input}}\n",
        "\n",
        "    def execute(self, plan: Dict[str, Any]) -> Tuple[str, Optional[str], List[Dict[str,str]]]:\n",
        "        tool = plan[\"tool\"]\n",
        "        args = plan.get(\"args\", {})\n",
        "        if tool == \"qa\":\n",
        "            ans, cites = self.tools.tool_project_qa(**args)\n",
        "            return ans, None, cites\n",
        "        if tool == \"sd\":\n",
        "            fname = self.tools.tool_sd_generate(**args)\n",
        "            return f\"Generated image: {fname}\", fname, []\n",
        "        if tool == \"calc\":\n",
        "            out = self.tools.tool_calculator(**args)\n",
        "            return f\"Calculator: {out}\", None, []\n",
        "        if tool == \"csv\":\n",
        "            out = self.tools.tool_csv_summary(**args)\n",
        "            return f\"CSV summary: {out}\", None, []\n",
        "        return \"Unknown tool.\", None, []\n",
        "\n",
        "    def aggregate(self, final_chunks: List[str]) -> str:\n",
        "        return \"\\n---\\n\".join(final_chunks)\n",
        "\n",
        "    def run(self, user_input: str, deadline_ts: float) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Runs up to MAX_HOPS or until deadline; returns trace dict.\n",
        "        \"\"\"\n",
        "        guard = blocked_by_guardrails(user_input)\n",
        "        if guard:\n",
        "            return {\n",
        "                \"final\": f\"Blocked by guardrails: {guard}\",\n",
        "                \"hops\": [], \"citations\": [], \"image\": None, \"latency_ms\": 0\n",
        "            }\n",
        "\n",
        "        hops_trace = []\n",
        "        chunks = []\n",
        "        citations: List[Dict[str,str]] = []\n",
        "        produced_image = None\n",
        "\n",
        "        for hop in range(MAX_HOPS):\n",
        "            if time.time() > deadline_ts:\n",
        "                chunks.append(\"⏰ Stopped: deadline reached.\")\n",
        "                break\n",
        "            t0 = time.time()\n",
        "            plan = self.plan(user_input, hop)\n",
        "            text, image, cites = self.execute(plan)\n",
        "            dt = int((time.time() - t0) * 1000)\n",
        "            hops_trace.append({\n",
        "                \"tool\": plan[\"tool\"],\n",
        "                \"input\": plan.get(\"args\", {}),\n",
        "                \"output_preview\": (image or text)[:200],\n",
        "                \"latency_ms\": dt\n",
        "            })\n",
        "            if image and not produced_image:\n",
        "                produced_image = image\n",
        "            if cites:\n",
        "                citations.extend(cites)\n",
        "            chunks.append(text)\n",
        "\n",
        "            # Simple early stop: if we generated an image or answered QA, stop.\n",
        "            if plan[\"tool\"] in (\"sd\", \"qa\"):\n",
        "                break\n",
        "\n",
        "        final = self.aggregate(chunks)\n",
        "        latency_total = sum(h[\"latency_ms\"] for h in hops_trace)\n",
        "\n",
        "        return {\n",
        "            \"final\": final, \"hops\": hops_trace, \"citations\": citations,\n",
        "            \"image\": produced_image, \"latency_ms\": latency_total\n",
        "        }\n",
        "\n",
        "# --------------- Persistent trace log ---------------\n",
        "def append_trace(root: Path, user_input: str, trace: Dict[str, Any]):\n",
        "    out = root / \"screenshots\" / \"agent_traces.jsonl\"\n",
        "    out.parent.mkdir(parents=True, exist_ok=True)\n",
        "    row = {\n",
        "        \"id\": uuid.uuid4().hex,\n",
        "        \"ts\": int(time.time()),\n",
        "        \"input\": user_input,\n",
        "        \"trace\": trace\n",
        "    }\n",
        "    with out.open(\"a\", encoding=\"utf-8\") as f:\n",
        "        f.write(json.dumps(row) + \"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "565403f0"
      },
      "source": [
        "import os\n",
        "\n",
        "os.makedirs('Week_7/backend', exist_ok=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile Week_7/backend/main.py\n",
        "import time, os, uuid, json\n",
        "from pathlib import Path\n",
        "from typing import List, Optional, Dict\n",
        "from fastapi import FastAPI, HTTPException, Header\n",
        "from pydantic import BaseModel, Field\n",
        "import torch\n",
        "from PIL import Image\n",
        "\n",
        "# Local modules\n",
        "from .settings import settings\n",
        "from .agent_runtime import Tools, Agent, append_trace, blocked_by_guardrails, MAX_HOPS, REQ_TIMEOUT\n",
        "\n",
        "ROOT = Path(__file__).resolve().parents[1]\n",
        "OUT_DIR = ROOT / \"diffusion\"\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "CFG = json.loads((ROOT/\"week7_run_config.json\").read_text())\n",
        "\n",
        "MODEL_ID = CFG[\"model_id\"]\n",
        "NEGATIVE = CFG[\"negative_prompt\"]\n",
        "SD_STEPS = int(CFG[\"sd_steps\"])\n",
        "SD_GUIDE = float(CFG[\"sd_guidance\"])\n",
        "W, H = CFG[\"size\"]\n",
        "\n",
        "# ------- SD pipeline (lazy) ----------\n",
        "_sd_pipe = None\n",
        "def get_sd():\n",
        "    global _sd_pipe\n",
        "    if _sd_pipe is None:\n",
        "        from diffusers import StableDiffusionPipeline\n",
        "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        _sd_pipe = StableDiffusionPipeline.from_pretrained(\n",
        "            MODEL_ID,\n",
        "            torch_dtype=torch.float16 if device==\"cuda\" else torch.float32\n",
        "        )\n",
        "        if device == \"cuda\":\n",
        "            _sd_pipe.enable_attention_slicing()\n",
        "            _sd_pipe.to(device)\n",
        "    return _sd_pipe\n",
        "\n",
        "def sd_generate_callable(prompt: str, negative_prompt: str, steps: int, guidance: float, height: int, width: int, filename_prefix: str = \"agent\") -> str:\n",
        "    \"\"\"Wrapper used by Tools to generate & save an image; returns filename only.\"\"\"\n",
        "    pipe = get_sd()\n",
        "    img = pipe(\n",
        "        prompt=prompt,\n",
        "        negative_prompt=negative_prompt,\n",
        "        num_inference_steps=steps or SD_STEPS,\n",
        "        guidance_scale=guidance or SD_GUIDE,\n",
        "        height=height or H,\n",
        "        width=width or W\n",
        "    ).images[0]\n",
        "    fname = f\"{filename_prefix}_{uuid.uuid4().hex[:8]}.png\"\n",
        "    img.save(OUT_DIR / fname)\n",
        "    return fname\n",
        "\n",
        "# ------- Auth & Guardrails ----------\n",
        "def require_auth(authorization: str | None = Header(default=None)):\n",
        "    token = settings.app_api_token\n",
        "    if not token:\n",
        "        return\n",
        "    if not authorization or not authorization.startswith(\"Bearer \"):\n",
        "        raise HTTPException(status_code=401, detail=\"Missing bearer token\")\n",
        "    if authorization.split(\" \", 1)[1].strip() != token:\n",
        "        raise HTTPException(status_code=403, detail=\"Invalid token\")\n",
        "\n",
        "def guardrails(text: str):\n",
        "    bad = blocked_by_guardrails(text)\n",
        "    if bad:\n",
        "        raise HTTPException(status_code=400, detail=f\"Blocked by guardrails: {bad}\")\n",
        "\n",
        "# ------- Pydantic Schemas ----------\n",
        "class QARequest(BaseModel):\n",
        "    query: str = Field(...)\n",
        "\n",
        "class QAResponse(BaseModel):\n",
        "    answer: str\n",
        "    citations: List[Dict[str,str]]\n",
        "    latency_ms: int\n",
        "\n",
        "class GenRequest(BaseModel):\n",
        "    prompt: str\n",
        "    negative_prompt: Optional[str] = NEGATIVE\n",
        "    steps: Optional[int] = SD_STEPS\n",
        "    guidance: Optional[float] = SD_GUIDE\n",
        "    height: Optional[int] = H\n",
        "    width: Optional[int] = W\n",
        "\n",
        "class GenResponse(BaseModel):\n",
        "    filename: str\n",
        "    latency_ms: int\n",
        "\n",
        "class AgentRequest(BaseModel):\n",
        "    input: str\n",
        "\n",
        "class AgentHop(BaseModel):\n",
        "    tool: str\n",
        "    input: Dict\n",
        "    output_preview: str\n",
        "    latency_ms: int\n",
        "\n",
        "class AgentResponse(BaseModel):\n",
        "    final: str\n",
        "    hops: List[AgentHop]\n",
        "    citations: List[Dict[str,str]] = []\n",
        "    image_filename: Optional[str] = None\n",
        "    latency_ms: int\n",
        "\n",
        "# ------- App ----------\n",
        "app = FastAPI(title=\"Week 7 Backend\", version=\"2.0\")\n",
        "\n",
        "@app.get(\"/health\")\n",
        "def health():\n",
        "    return {\"ok\": True, \"model\": MODEL_ID, \"agent\": True}\n",
        "\n",
        "# ---- Stub QA (existing) ----\n",
        "def project_qa(query: str):\n",
        "    ans = f\"Stubbed answer for: {query} (replace with your Graph-RAG/Multi-Hop).\"\n",
        "    cites = [\n",
        "        {\"title\": \"Week 7 Repo\", \"url\": \"https://github.com/sudhakarjerribanda/Capston_Handson/tree/main/Week_7\"},\n",
        "        {\"title\": \"Task 1 Colab\", \"url\": \"https://colab.research.google.com/drive/1yZd5zUUmNjeDH-_mpVEkNCO4fonsmW69?usp=sharing\"}\n",
        "    ]\n",
        "    return ans, cites\n",
        "\n",
        "@app.post(\"/qa\", response_model=QAResponse)\n",
        "def qa(req: QARequest, _=require_auth()):\n",
        "    t0 = time.time()\n",
        "    guardrails(req.query)\n",
        "    ans, cites = project_qa(req.query)\n",
        "    return QAResponse(answer=ans, citations=cites, latency_ms=int((time.time()-t0)*1000))\n",
        "\n",
        "@app.post(\"/generate\", response_model=GenResponse)\n",
        "def generate(req: GenRequest, _=require_auth()):\n",
        "    t0 = time.time()\n",
        "    guardrails(req.prompt)\n",
        "    fname = sd_generate_callable(\n",
        "        prompt=req.prompt,\n",
        "        negative_prompt=req.negative_prompt or NEGATIVE,\n",
        "        steps=req.steps or SD_STEPS,\n",
        "        guidance=req.guidance or SD_GUIDE,\n",
        "        height=req.height or H,\n",
        "        width=req.width or W,\n",
        "        filename_prefix=\"api\"\n",
        "    )\n",
        "    return GenResponse(filename=fname, latency_ms=int((time.time()-t0)*1000))\n",
        "\n",
        "# ---- Real Agent Endpoint ----\n",
        "@app.post(\"/agent\", response_model=AgentResponse)\n",
        "def agent(req: AgentRequest, _=require_auth()):\n",
        "    guardrails(req.input)\n",
        "    # Make tools & agent\n",
        "    tools = Tools(sd_callable=sd_generate_callable, negative_prompt=NEGATIVE, size=(W, H))\n",
        "    agent = Agent(tools)\n",
        "    deadline = time.time() + REQ_TIMEOUT\n",
        "\n",
        "    trace = agent.run(req.input, deadline_ts=deadline)\n",
        "    append_trace(ROOT, req.input, trace)\n",
        "\n",
        "    hops = [AgentHop(tool=h[\"tool\"], input=h[\"input\"], output_preview=h[\"output_preview\"], latency_ms=h[\"latency_ms\"]) for h in trace[\"hops\"]]\n",
        "    return AgentResponse(\n",
        "        final=trace[\"final\"],\n",
        "        hops=hops,\n",
        "        citations=trace.get(\"citations\", []),\n",
        "        image_filename=trace.get(\"image\"),\n",
        "        latency_ms=trace.get(\"latency_ms\", 0)\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8R_POATau7H",
        "outputId": "09c21330-672c-4180-b23e-3ccb2bd89bc2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing Week_7/backend/main.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## B) Restart backend (same tunnel helper from Task-B)"
      ],
      "metadata": {
        "id": "wEkiWvkmbbSA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Restart the backend & re-expose (uses your existing expose_port helper if defined)\n",
        "import nest_asyncio, uvicorn, threading, time, os, re, subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "# Start FastAPI\n",
        "nest_asyncio.apply()\n",
        "def run_api():\n",
        "    import Week_7.backend.main as api\n",
        "    uvicorn.run(\"Week_7.backend.main:app\", host=\"0.0.0.0\", port=8000, log_level=\"info\")\n",
        "thread = threading.Thread(target=run_api, daemon=True); thread.start()\n",
        "time.sleep(2)\n",
        "\n",
        "# Expose port 8000 (ngrok if token, else cloudflared). If expose_port not defined, define fallback.\n",
        "if \"expose_port\" not in globals():\n",
        "    def _ensure_cloudflared():\n",
        "        if not Path(\"cloudflared\").exists():\n",
        "            !curl -L https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -o cloudflared -#\n",
        "            !chmod +x cloudflared\n",
        "    def expose_port(port: int):\n",
        "        _ensure_cloudflared()\n",
        "        proc = subprocess.Popen(\n",
        "            [\"./cloudflared\", \"tunnel\", \"--url\", f\"http://127.0.0.1:{port}\", \"--no-autoupdate\"],\n",
        "            stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, bufsize=1\n",
        "        )\n",
        "        public_url = None; start = time.time()\n",
        "        while time.time() - start < 30:\n",
        "            line = proc.stdout.readline()\n",
        "            if not line: time.sleep(0.1); continue\n",
        "            m = re.search(r\"https://[-\\w]+\\.trycloudflare\\.com\", line.strip())\n",
        "            if m: public_url = m.group(0); break\n",
        "        if not public_url:\n",
        "            proc.terminate(); raise RuntimeError(\"cloudflared did not produce a public URL in time.\")\n",
        "        return public_url, proc\n",
        "\n",
        "backend_url, backend_proc = expose_port(8000)\n",
        "Path(\"BACKEND_URL.txt\").write_text(backend_url)\n",
        "print(\"✅ Backend:\", backend_url)\n",
        "print(\"   Health:\", f\"{backend_url}/health\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_fQ_BbtbJmR",
        "outputId": "9732e4aa-530b-4c0b-be75-48ade7e0489c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#=#=#                                                                         \r##O#-#                                                                        \r##O=#  #                                                                      \r#=#=-#  #                                                                     \r\r                                                                           0.0%\r                                                                           0.4%\r##                                                                         2.9%\r##                                                                         4.1%\r########                                                                  12.2%\r#############                                                             19.3%\r###################                                                       27.2%\r########################                                                  34.0%\r#############################                                             40.7%\r#################################                                         46.2%\r####################################                                      51.4%\r########################################                                  56.4%\r############################################                              61.4%\r##############################################                            64.7%\r##################################################                        70.7%\r#####################################################                     74.4%\r########################################################                  78.6%\r###########################################################               82.5%\r##############################################################            86.8%\r#################################################################         90.9%\r####################################################################      95.0%\r#######################################################################   99.4%\r######################################################################## 100.0%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-3 (run_api):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.12/threading.py\", line 1012, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/tmp/ipython-input-3707022144.py\", line 8, in run_api\n",
            "  File \"/content/Week_7/backend/main.py\", line 10, in <module>\n",
            "    from .settings import settings\n",
            "ModuleNotFoundError: No module named 'Week_7.backend.settings'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Backend: https://susan-jessica-responded-proposed.trycloudflare.com\n",
            "   Health: https://susan-jessica-responded-proposed.trycloudflare.com/health\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## C) Five agent test queries (trace-friendly & JSON-safe)"
      ],
      "metadata": {
        "id": "8Dh5TFCQbXmE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json, requests, textwrap\n",
        "from pathlib import Path\n",
        "\n",
        "BASE = Path(\"BACKEND_URL.txt\").read_text().strip().rstrip(\"/\")\n",
        "headers = {\"Authorization\": f\"Bearer {os.environ['APP_API_TOKEN']}\"} if os.environ.get(\"APP_API_TOKEN\") else {}\n",
        "\n",
        "def post_json(path, payload, timeout=180):\n",
        "    url = f\"{BASE}{path}\"\n",
        "    r = requests.post(url, json=payload, headers=headers, timeout=timeout)\n",
        "    ct = (r.headers.get(\"content-type\") or \"\").lower()\n",
        "    print(f\"\\nPOST {url} -> {r.status_code} {ct}\")\n",
        "    if \"application/json\" in ct:\n",
        "        data = r.json()\n",
        "        print(json.dumps(data, indent=2)[:600], \"...\")\n",
        "        return data\n",
        "    else:\n",
        "        print(textwrap.shorten(r.text.replace(\"\\n\",\" \"), width=400))\n",
        "        return None\n",
        "\n",
        "tests = [\n",
        "    {\"input\": \"Generate an infographic of a trust game with BDI panels and reciprocity gauge\"},\n",
        "    {\"input\": \"Explain Graph-RAG evidence integration for IMRaD sections\"},\n",
        "    {\"input\": \"calc: (1+2*3)^2 / 7\"},\n",
        "    {\"input\": \"CSV: colA,colB\\n1,10\\n2,20\\n3,30\"},\n",
        "    {\"input\": \"Create a clean isometric diagram of recruiter → MDT → ICT triage flow\"}\n",
        "]\n",
        "\n",
        "results = []\n",
        "for t in tests:\n",
        "    data = post_json(\"/agent\", t, timeout=240)\n",
        "    results.append(data)\n",
        "print(\"\\n✅ Ran 5 agent queries.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eu7W-dHbNWd",
        "outputId": "10a441c3-5dfd-469f-f52f-5117a3357ca5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "POST https://susan-jessica-responded-proposed.trycloudflare.com/agent -> 502 text/plain; charset=utf-8\n",
            "502 Bad Gateway Unable to reach the origin service. The service may be down or it may not be responding to traffic from cloudflared\n",
            "\n",
            "POST https://susan-jessica-responded-proposed.trycloudflare.com/agent -> 502 text/plain; charset=utf-8\n",
            "502 Bad Gateway Unable to reach the origin service. The service may be down or it may not be responding to traffic from cloudflared\n",
            "\n",
            "POST https://susan-jessica-responded-proposed.trycloudflare.com/agent -> 502 text/plain; charset=utf-8\n",
            "502 Bad Gateway Unable to reach the origin service. The service may be down or it may not be responding to traffic from cloudflared\n",
            "\n",
            "POST https://susan-jessica-responded-proposed.trycloudflare.com/agent -> 502 text/plain; charset=utf-8\n",
            "502 Bad Gateway Unable to reach the origin service. The service may be down or it may not be responding to traffic from cloudflared\n",
            "\n",
            "POST https://susan-jessica-responded-proposed.trycloudflare.com/agent -> 502 text/plain; charset=utf-8\n",
            "502 Bad Gateway Unable to reach the origin service. The service may be down or it may not be responding to traffic from cloudflared\n",
            "\n",
            "✅ Ran 5 agent queries.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tI1YIbAAbJ3s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}